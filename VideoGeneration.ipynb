{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HCNwdjFIpuY"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F5LnO_fIIV4C"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U pandas google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "D70f8knYVdAG",
    "outputId": "5d9bfc4d-8e6f-4673-976c-4779bcb90d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elevenlabs in /usr/local/lib/python3.12/dist-packages (2.23.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (0.28.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (2.11.10)\n",
      "Requirement already satisfied: pydantic-core>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (2.33.2)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (2.32.4)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (4.15.0)\n",
      "Requirement already satisfied: websockets>=11.0 in /usr/local/lib/python3.12/dist-packages (from elevenlabs) (15.0.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->elevenlabs) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->elevenlabs) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->elevenlabs) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.21.2->elevenlabs) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.21.2->elevenlabs) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->elevenlabs) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9.2->elevenlabs) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->elevenlabs) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->elevenlabs) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.21.2->elevenlabs) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "udJcHMJ8Vg5U",
    "outputId": "589f9611-920c-45d0-f090-7f1ac87af3ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (0.35.2)\n",
      "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers) (8.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from diffusers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from diffusers) (0.36.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from diffusers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from diffusers) (2.32.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.12/dist-packages (from diffusers) (0.6.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from diffusers) (11.3.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (6.0.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.34.0->diffusers) (1.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->diffusers) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ofC1E6hMVEGr",
    "outputId": "7f577394-d4ee-4644-cb65-fb4233a4c9f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "xqvQt49hU7aB",
    "outputId": "5af34cf7-178d-402c-f061-113f66e98b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.2)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Rg6qiNeIImFJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import google.generativeai as genai\n",
    "import json\n",
    "from google.colab import userdata\n",
    "from elevenlabs.client import ElevenLabs\n",
    "import torch\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "import sys\n",
    "from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips, concatenate_audioclips\n",
    "import moviepy.video.fx.all as vfx\n",
    "import os\n",
    "import time\n",
    "from google.api_core import exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U47UpvYWHX5K"
   },
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1Euhe5hJI3AC"
   },
   "outputs": [],
   "source": [
    "def load_and_process_data():\n",
    "    \"\"\"Uploads ONE OR MORE CSV files and processes them.\"\"\"\n",
    "    print(\"Please upload all your .csv files:\")\n",
    "    uploaded = files.upload() # This can now accept multiple files\n",
    "\n",
    "    if not uploaded:\n",
    "        print(\"No files uploaded. Exiting.\")\n",
    "        return None\n",
    "\n",
    "    all_dataframes = [] # A list to hold each dataframe\n",
    "\n",
    "    # Loop through all uploaded files\n",
    "    for filename, content in uploaded.items():\n",
    "        print(f\"Reading file: {filename}...\")\n",
    "        try:\n",
    "            from io import BytesIO\n",
    "            df_temp = pd.read_csv(BytesIO(content))\n",
    "\n",
    "            if 'decade' not in df_temp.columns or 'summary' not in df_temp.columns:\n",
    "                print(f\"  WARNING: File '{filename}' is missing 'decade' or 'summary'. Skipping this file.\")\n",
    "                continue\n",
    "\n",
    "            all_dataframes.append(df_temp)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error reading {filename}: {e}\")\n",
    "\n",
    "    if not all_dataframes:\n",
    "        print(\"No valid dataframes were loaded. Exiting.\")\n",
    "        return None\n",
    "\n",
    "    # Merge all individual dataframes into one master dataframe\n",
    "    df_master = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    decade_data = df_master.groupby('decade')['summary'].apply(' '.join)\n",
    "\n",
    "    print(\"\\n--- All Decades Found and Processed ---\")\n",
    "    print(decade_data)\n",
    "    return decade_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7YHuWJeI9Hq"
   },
   "source": [
    "# Load All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VSQb10_zOj-6"
   },
   "outputs": [],
   "source": [
    "def get_elevenlabs_voices(client):\n",
    "    \"\"\"\n",
    "    Fetches all premade voices from ElevenLabs and formats them\n",
    "    as a string for the AI Director.\n",
    "    \"\"\"\n",
    "    print(\"Fetching available ElevenLabs voices...\")\n",
    "    try:\n",
    "        voices_string_list = []\n",
    "        all_voices = client.voices.get_all().voices\n",
    "\n",
    "        for voice in all_voices:\n",
    "            if voice.category == 'premade':\n",
    "                # Format the labels (e.g., {'age': 'middle_aged', 'accent': 'american'})\n",
    "                # This gives the AI context on what the voice sounds like\n",
    "                labels = \", \".join(f\"{k}: {v}\" for k, v in voice.labels.items())\n",
    "                voices_string_list.append(\n",
    "                    f'Name: {voice.name} (ID: {voice.voice_id}) - Description: {labels}'\n",
    "                )\n",
    "\n",
    "        print(f\"Found {len(voices_string_list)} premade voices.\")\n",
    "        return \"\\n\".join(voices_string_list)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching ElevenLabs voices: {e}\")\n",
    "        return None # Handle this error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "O7auSUSXI_Co"
   },
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    \"\"\"Loads API keys and AI models (SDXL-only).\"\"\"\n",
    "    print(\"Loading API keys...\")\n",
    "    try:\n",
    "        # genai.configure(api_key=userdata.get('GEMINI_API_KEY'))\n",
    "        genai.configure(api_key=userdata.get('GEMINI_API_KEY2'))\n",
    "        elevenlabs_client = ElevenLabs(api_key=userdata.get('ELEVENLAB_KEY'))\n",
    "        # if not using colab secrets\n",
    "        # GEMINI_API_KEY = \" \" #<- input your key here\n",
    "        # ELEVENLAB_KEY = \" \" #<- input your key here\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading API keys from Secrets: {e}\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"Loading AI Director model (Gemini 2.5 Pro)...\")\n",
    "    director_model = genai.GenerativeModel('gemini-2.5-pro')\n",
    "\n",
    "    print(\"Loading AI Artist model (SDXL)... This may take a few minutes.\")\n",
    "    torch.cuda.empty_cache()\n",
    "    try:\n",
    "        artist_pipe = AutoPipelineForText2Image.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "            dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True\n",
    "        ).to(\"cuda\")\n",
    "        # An A100 can handle this without offload, making it faster\n",
    "        # artist_pipe.enable_model_cpu_offload()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SDXL model: {e}\")\n",
    "        sys.exit()\n",
    "\n",
    "    print(\"Fetching available ElevenLabs voices...\")\n",
    "    voice_list_string = get_elevenlabs_voices(elevenlabs_client) # Assumes your 'fallback' version\n",
    "\n",
    "    print(\"--- All models initialized successfully ---\")\n",
    "\n",
    "    return director_model, elevenlabs_client, artist_pipe, voice_list_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNFxdU0bXEFx"
   },
   "source": [
    "# The AI \"Director\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "93NLGPFKJFam"
   },
   "outputs": [],
   "source": [
    "def run_director_step(decade, facts_string, model, voice_list_string):\n",
    "    \"\"\"\n",
    "    Step 2: Calls Gemini with a \"brute force\" auto-retry logic\n",
    "    that CHECKS THE ERROR MESSAGE for \"429\" or \"quota\".\n",
    "    \"\"\"\n",
    "    print(f\"Directing script for {decade}s...\")\n",
    "\n",
    "    # (Prompt setup code)\n",
    "    text_length = len(facts_string)\n",
    "    if text_length < 500: scene_count = 5\n",
    "    elif text_length < 1500: scene_count = 7\n",
    "    else: scene_count = 10\n",
    "    print(f\"Input facts length is {text_length}. Requesting {scene_count} scenes.\")\n",
    "    scene_examples = []\n",
    "    for i in range(1, scene_count + 1):\n",
    "        scene_examples.append(\n",
    "            f'{{ \"scene\": {i}, \"narration_cue\": \"The narration for this scene only.\", \"artist_prompt\": \"...\" }}'\n",
    "        )\n",
    "    schema_example_scenes = \",\\n        \".join(scene_examples)\n",
    "    director_system_prompt = f\"\"\"\n",
    "    You are an AI \"Director\" for a historical documentary.\n",
    "    Your job is to take raw historical facts from the {decade}s, write a script, AND cast the narrator.\n",
    "    ---\n",
    "    AVAILABLE NARRATOR VOICES:\n",
    "    {voice_list_string}\n",
    "    ---\n",
    "    TASK:\n",
    "    1. Analyze the facts and the {decade}s.\n",
    "    2. Write a script with **exactly {scene_count} scenes**.\n",
    "    3. From the \"AVAILABLE NARRATOR VOICES\" list, select the *single best voice*.\n",
    "    4. **CRITICAL:** The 'narration_script' must be the *full* script. The 'narration_cue' for *each scene* must be the *exact* portion of the script for that scene. Do not overlap cues.\n",
    "    5. **NEW RULE:** If a scene prompt is about a **map**, add \"highly detailed antique map, flat illustration style, cartography\" to the. For all other scenes, use \"dramatic, cinematic digital painting\".\n",
    "    6. Output a single JSON object. Do not include '```json' or any other text.\n",
    "    The JSON must have this exact schema:\n",
    "    {{\n",
    "      \"title\": \"A short, catchy video title about the {decade}s\",\n",
    "      \"voice_id\": \"The chosen 'ID' (e.g., 'pNInz6obpgDQGcFmaJgB') from the voice list\",\n",
    "      \"narration_script\": \"The complete narration script, as one string.\",\n",
    "      \"scenes\": [\n",
    "        {schema_example_scenes}\n",
    "      ]\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- NEW: Improved Retry Logic ---\n",
    "    total_attempts = 3 # We will try 3 times total\n",
    "\n",
    "    for i in range(total_attempts):\n",
    "        try:\n",
    "            # Try to run the generation\n",
    "            response = model.generate_content(\n",
    "                [director_system_prompt, facts_string],\n",
    "                generation_config=genai.types.GenerationConfig(\n",
    "                    response_mime_type=\"application/json\"\n",
    "                )\n",
    "            )\n",
    "            # If it succeeds, load the JSON\n",
    "            video_plan = json.loads(response.text)\n",
    "\n",
    "            # If *that* succeeds, we are done\n",
    "            print(f\"Title: {video_plan['title']} ({len(video_plan['scenes'])} scenes)\")\n",
    "            print(f\"AI-Selected Voice ID: {video_plan['voice_id']}\")\n",
    "            return video_plan # Success!\n",
    "\n",
    "        except Exception as e:\n",
    "            # --- THIS IS THE NEW \"BRUTE FORCE\" CATCH-ALL ---\n",
    "            error_message = str(e)\n",
    "\n",
    "            # Check if the error text is a rate-limit error\n",
    "            is_rate_limit_error = \"429\" in error_message or \"quota\" in error_message.lower()\n",
    "\n",
    "            if is_rate_limit_error:\n",
    "                # It's a rate limit, let's try to wait\n",
    "                print(f\"  Server rate limit detected for {decade}.\")\n",
    "\n",
    "                if i < total_attempts - 1: # Check if we have retries left (e.g., i is 0 or 1)\n",
    "                    wait_time = 65 # 65 seconds\n",
    "                    print(f\"  Waiting {wait_time}s to retry ({i+1}/{total_attempts} attempts)...\")\n",
    "                    time.sleep(wait_time)\n",
    "                    print(\"  Retrying...\")\n",
    "                else:\n",
    "                    # This was the last attempt\n",
    "                    print(\"  No retries left. Failing this decade.\")\n",
    "                    raise e # Re-raise the error to be caught by main()\n",
    "\n",
    "            else:\n",
    "                # This is a *different* error (like bad JSON from Gemini)\n",
    "                # We should NOT retry these.\n",
    "                print(f\"  Failed with non-retryable error: {e}\")\n",
    "                raise e # Fail immediately\n",
    "\n",
    "    # If the loop finishes without returning, it means all retries failed\n",
    "    raise Exception(f\"Max {total_attempts} retries exceeded for Gemini API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RemIVEVlXQxn"
   },
   "source": [
    "# The Narration Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Yd3R3RDwJNWz"
   },
   "outputs": [],
   "source": [
    "def run_narrator_step(video_plan, client, output_dir):\n",
    "    \"\"\"\n",
    "    Step 3: Generates a SEPARATE audio file for EACH scene cue.\n",
    "    Returns a list of audio file paths.\n",
    "    \"\"\"\n",
    "    print(\"Generating audio for each scene...\")\n",
    "\n",
    "    audio_files = [] # This will be a list\n",
    "    voice_to_use = video_plan.get('voice_id', \"pNInz6obpgDQGcFmaJgB\") # Get voice, with fallback\n",
    "\n",
    "    print(f\"Using AI-selected voice ID: {voice_to_use}\")\n",
    "\n",
    "    for scene in video_plan['scenes']:\n",
    "        scene_number = scene['scene']\n",
    "        narration_text = scene['narration_cue']\n",
    "\n",
    "        # We need to make sure the AI didn't give us an empty cue\n",
    "        if not narration_text or len(narration_text.strip()) < 2:\n",
    "            print(f\"  Warning: Scene {scene_number} has no narration cue. Skipping audio.\")\n",
    "            continue\n",
    "\n",
    "        audio_filename = os.path.join(output_dir, f\"narration_scene_{scene_number}.mp3\")\n",
    "\n",
    "        try:\n",
    "            audio = client.text_to_speech.convert(\n",
    "                text=narration_text,\n",
    "                voice_id=voice_to_use,\n",
    "                model_id=\"eleven_multilingual_v2\"\n",
    "            )\n",
    "\n",
    "            with open(audio_filename, \"wb\") as f:\n",
    "                for chunk in audio:\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "\n",
    "            audio_files.append(audio_filename)\n",
    "            print(f\"  Audio saved as {audio_filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating audio for scene {scene_number}: {e}\")\n",
    "\n",
    "    return audio_files # Returns the list of paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGBzW_1mamd9"
   },
   "source": [
    "# The AI \"Artist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mCfPwqkZJSMa"
   },
   "outputs": [],
   "source": [
    "def run_artist_step(video_plan, pipe, output_dir):\n",
    "    \"\"\"Step 4: Calls SDXL to generate high-quality STATIC images.\"\"\"\n",
    "    print(\"Generating static images...\")\n",
    "    image_files = [] # This will be a list of .png files\n",
    "\n",
    "    for scene in video_plan['scenes']:\n",
    "        prompt = scene['artist_prompt']\n",
    "        scene_number = scene['scene']\n",
    "\n",
    "        # We save as .png, not _still.png\n",
    "        scene_filename = os.path.join(output_dir, f\"scene_{scene_number}.png\")\n",
    "        neg_prompt = \"cartoon, cgi, blurry, low-resolution, disfigured, (watermark:1.3), text, deformed, ugly\"\n",
    "\n",
    "        print(f\"Generating image for scene {scene_number}...\")\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            negative_prompt=neg_prompt,\n",
    "            num_inference_steps=25\n",
    "        ).images[0]\n",
    "\n",
    "        image.save(scene_filename)\n",
    "        image_files.append(scene_filename)\n",
    "        print(f\"Saved {scene_filename}\")\n",
    "\n",
    "    return image_files # Returns a list of .png paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbsdc9uBbYgr"
   },
   "source": [
    "# The AI \"Editor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "uQJ81-zdJZOe"
   },
   "outputs": [],
   "source": [
    "def run_editor_step(video_plan, decade, image_files, narration_files, main_output_dir):\n",
    "    \"\"\"\n",
    "    Step 5: Assembles video with PERFECT sync (Static images, no zoom).\n",
    "    Matches each image's duration to its corresponding audio clip.\n",
    "    \"\"\"\n",
    "    print(\"Assembling video with perfect sync (static images)...\")\n",
    "\n",
    "    # Check for mismatches\n",
    "    if not image_files or not narration_files or len(image_files) != len(narration_files):\n",
    "        print(f\"  Error: Mismatch in scene count.\")\n",
    "        print(f\"  Found {len(image_files)} images and {len(narration_files)} audio clips.\")\n",
    "        print(\"  Skipping video assembly.\")\n",
    "        return None\n",
    "\n",
    "    scene_clips = []    # To hold video clips\n",
    "    audio_clips = []    # To hold audio clips\n",
    "\n",
    "    # Loop and match pairs\n",
    "    for img_file, aud_file in zip(image_files, narration_files):\n",
    "        try:\n",
    "            # 1. Load the audio clip and get its exact duration\n",
    "            audio_clip = AudioFileClip(aud_file)\n",
    "            scene_duration = audio_clip.duration\n",
    "            audio_clips.append(audio_clip) # Add to our list\n",
    "\n",
    "            # 2. Load the image clip\n",
    "            img_clip = ImageClip(img_file)\n",
    "\n",
    "            # --- ZOOM REMOVED ---\n",
    "            # img_clip = img_clip.resize(width=img_clip.w * 1.1)\n",
    "            # img_clip = img_clip.resize(lambda t: 1 - (t * 0.05))\n",
    "\n",
    "            # We keep this to ensure it's centered\n",
    "            img_clip = img_clip.set_position((\"center\", \"center\"))\n",
    "\n",
    "            # 3. Set the image duration to MATCH the audio duration\n",
    "            img_clip = img_clip.set_duration(scene_duration)\n",
    "\n",
    "            # Add fades\n",
    "            fade_time = min(0.5, scene_duration / 4)\n",
    "            img_clip = img_clip.fadein(fade_time).fadeout(fade_time)\n",
    "\n",
    "            scene_clips.append(img_clip)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing clip {img_file}: {e}\")\n",
    "\n",
    "    if not scene_clips:\n",
    "        print(\"No valid scenes were created. Skipping video.\")\n",
    "        return None\n",
    "\n",
    "    # 4. Stitch everything together\n",
    "    final_video_clip = concatenate_videoclips(scene_clips, method=\"compose\")\n",
    "    final_audio_clip = concatenate_audioclips(audio_clips)\n",
    "\n",
    "    final_clip = final_video_clip.set_audio(final_audio_clip)\n",
    "\n",
    "    safe_title = video_plan['title'].replace(' ', '_').replace(':', '_')\n",
    "    output_filename = os.path.join(main_output_dir, f\"{decade}_{safe_title}.mp4\")\n",
    "\n",
    "    final_clip.write_videofile(output_filename, fps=24, codec='libx264', logger=None)\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qFODPwZJaYi"
   },
   "source": [
    "# Main Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nAcvCS-BS7ap",
    "outputId": "b51f49e9-fa43-4034-cd5d-1ff550af400c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All output will be saved in the 'TroyHistory' folder.\n"
     ]
    }
   ],
   "source": [
    "MAIN_OUTPUT_FOLDER = \"TroyHistory\"\n",
    "os.makedirs(MAIN_OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"All output will be saved in the '{MAIN_OUTPUT_FOLDER}' folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uYw4mLj9n-n_"
   },
   "outputs": [],
   "source": [
    "all_summaries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "d21dce32259d4451ba2851598bbdfc22",
      "ad7e664f36be4184b617ff6221d757e6",
      "e16bc5ac430f44f0af54eb0375ced6af",
      "f1e9a9e669e74ef6b81d5c8dfb9188e4",
      "f47b990e1d9945939d2f140f6805690d",
      "28980261df1b4bf6b5c60b0ceba9810f",
      "0cddc48d883f40b0a68680bd55543b24",
      "f7987f05ad1842e4885ea0f3ac28603c",
      "8333af6425514da7a58e5c47e298a018",
      "08baf04bc2ed4806ad6181c16cd1db9f",
      "da40e58360c4462883cf291f6faef066"
     ]
    },
    "collapsed": true,
    "id": "f8h5Kqx1dlSQ",
    "outputId": "ba732ac3-19de-47d5-ace9-7208ea298f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please upload all your .csv files:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-90171e48-44ea-47c7-985b-2cda12bb104c\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-90171e48-44ea-47c7-985b-2cda12bb104c\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving troy_history_by_decade_podcast.csv to troy_history_by_decade_podcast (2).csv\n",
      "Saving troy_history_by_decade_from_web.csv to troy_history_by_decade_from_web (2).csv\n",
      "Saving troy_history_by_decade_book.csv to troy_history_by_decade_book (2).csv\n",
      "Reading file: troy_history_by_decade_podcast (2).csv...\n",
      "Reading file: troy_history_by_decade_from_web (2).csv...\n",
      "Reading file: troy_history_by_decade_book (2).csv...\n",
      "\n",
      "--- All Decades Found and Processed ---\n",
      "decade\n",
      "1500s    The early 1500s witnessed the initial European...\n",
      "1520s    The 1520s witnessed the start of French-sponso...\n",
      "1560s    The 1560s were a pivotal decade for European c...\n",
      "1600s    The 1600s in the Troy area began with a pivota...\n",
      "1610s    In 1614, Dutch traders, having reaped signific...\n",
      "1620s    The 1620s saw the official beginning of Dutch ...\n",
      "1630s    The 1630s marked the active establishment of N...\n",
      "1640s    The 1640s in the area around modern-day Troy, ...\n",
      "1650s    The 1650s saw the Dutch intensify their coloni...\n",
      "1660s    The 1660s marked a period of significant land ...\n",
      "1670s    During the 1670s, the future site of Troy, New...\n",
      "1680s    The 1680s began with notable concern among set...\n",
      "1690s    The 1690s brought a period of intense danger a...\n",
      "1700s    The early 1700s marked the foundational Europe...\n",
      "1710s    In the 1710s, the land destined to become Troy...\n",
      "1720s    In 1720, significant land developments laid th...\n",
      "1730s    The 1730s in the region surrounding what would...\n",
      "1740s    The provided historical account offers limited...\n",
      "1750s    The 1750s in the Troy area were marked by cont...\n",
      "1760s    In the 1760s, Dutch interests actively sought ...\n",
      "1770s    The 1770s in the Upper Hudson region were larg...\n",
      "1780s    The 1780s marked a period of evolving identity...\n",
      "1790s    The 1790s were a foundational decade for the a...\n",
      "1800s    The early to mid-1800s marked a foundational e...\n",
      "1810s    The 1810s were a transformative decade for Tro...\n",
      "1820s    The 1820s were a pivotal decade for Troy, New ...\n",
      "1830s    The 1830s were a formative decade for Troy, Ne...\n",
      "1840s    In the 1840s, Troy, New York, experienced sign...\n",
      "1850s    The 1850s marked a transformative decade for T...\n",
      "1860s    The 1860s were a transformative decade for Tro...\n",
      "1870s    The 1870s firmly established Troy's identity a...\n",
      "1880s    During the early 1880s, Troy enjoyed a unique,...\n",
      "1890s    The provided event sentences describe historic...\n",
      "1900s    The early 1900s brought significant expansion ...\n",
      "1910s    The 1910s in Troy, New York, saw a significant...\n",
      "1930s    The 1930s in Troy, New York, were marked by a ...\n",
      "1940s    The 1940s in Troy, New York, represented a per...\n",
      "1950s    The 1950s in Troy, New York, were characterize...\n",
      "1960s    The 1960s marked a period of national recognit...\n",
      "1970s    The 1970s in Troy, New York, were highlighted ...\n",
      "1980s    The 1980s in Troy, New York, featured notable ...\n",
      "1990s    In the 1990s, Troy, New York's RPI Field House...\n",
      "2000s    Based on the provided information, the 2000s i...\n",
      "2010s    The 2010s in Troy, NY, saw a major undertaking...\n",
      "2020s    The early 2020s in Troy, New York, saw discuss...\n",
      "Name: summary, dtype: object\n",
      "Loading API keys...\n",
      "Loading AI Director model (Gemini 2.5 Pro)...\n",
      "Loading AI Artist model (SDXL)... This may take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n",
      "\n",
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionXLPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21dce32259d4451ba2851598bbdfc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching available ElevenLabs voices...\n",
      "Fetching available ElevenLabs voices...\n",
      "Found 20 premade voices.\n",
      "--- All models initialized successfully ---\n"
     ]
    }
   ],
   "source": [
    "# --- Setup (Run once) ---\n",
    "try:\n",
    "    decade_data = load_and_process_data()\n",
    "    if decade_data is None:\n",
    "        print(\"Failed to load data. Exiting.\")\n",
    "\n",
    "    director_model, elevenlabs_client, artist_pipe, voice_list_string = initialize_models()\n",
    "except Exception as e:\n",
    "    print(f\"Error during setup: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7ZV7sB3UQF7",
    "outputId": "1a3cea8f-193a-4ee0-c187-f4b79d64c822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for existing summary file: TroyHistory/summary_of_all_videos.json...\n",
      "Loaded 44 summaries from existing JSON.\n",
      "Found 44 completed decades. Will skip them.\n"
     ]
    }
   ],
   "source": [
    "summary_filename = os.path.join(MAIN_OUTPUT_FOLDER, \"summary_of_all_videos.json\")\n",
    "completed_decades = set()\n",
    "print(f\"Checking for existing summary file: {summary_filename}...\")\n",
    "\n",
    "try:\n",
    "    if os.path.exists(summary_filename):\n",
    "        with open(summary_filename, 'r') as f:\n",
    "            all_summaries = json.load(f)\n",
    "            # Get completed decades from the summary\n",
    "            for item in all_summaries:\n",
    "                completed_decades.add(str(item['decade']))\n",
    "        print(f\"Loaded {len(all_summaries)} summaries from existing JSON.\")\n",
    "        print(f\"Found {len(completed_decades)} completed decades. Will skip them.\")\n",
    "    else:\n",
    "        print(\"No summary file found. Will generate all videos.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not parse summary.json. Will re-generate all videos. {e}\")\n",
    "    all_summaries = []\n",
    "    completed_decades = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "36caf37e098d413a9f6e3d2137e40a23",
      "332f02c15e0b458bb9d6481a85850ce9",
      "8789f4e3ffa54823bd03d9d4c749af18",
      "9a85ab99e5d243ceb70457b415407748",
      "6627061cea644c248f22715500558e2d",
      "928841e105c141e0a06a298c932273e8",
      "499f0bd6a92541b7a072d348d24fab8e",
      "905500a43ede4c6b8ba10760eaaa0420",
      "9c3ed3d8a5894528b871bdaf8ee29fec",
      "749be6c82bbc496a8f0c5c63d35c3c68",
      "d147ec61d26845fbaf73611dc98a7ec5",
      "756a1f1aece242ffb9f3ca3a739e9633",
      "506aa0273f914b399207713b3be1746a",
      "e0abc321213548cc8c825e0e7751f0d8",
      "2ea2932665d740fca9144f891e2f98d1",
      "727de1d66ae24df0917c2f0d9f22e570",
      "acc12792d8c1454da699b074b6b69706",
      "12e91289fdce4e278c67b94fb234c9cb",
      "3cd419f6c9f944cba5e30e9b2ed690ef",
      "f61b3a5b3e774cf38b309daadfba8c40",
      "585c6dbb7c454b9b959c8f6625283939",
      "6b368b8142414cd8a8a9b64aeff891e4",
      "0b7cbc446eef4979b4b5688df5c0467c",
      "96a24ef413d44fde92b5486f62f2b937",
      "c1e0d28041924558a76d08bb81d60842",
      "2c21f190cc6748d6bd57eb2984d5420f",
      "da71042777f34d608c250324099f474c",
      "dbfefddec74b4e589d3508581c40e994",
      "eda406b2c8a14edaae0c2e60a1f09f4f",
      "9b6db013f70c42589baa6571b52c17b0",
      "194a60af916e42a38d8f55bc89954311",
      "dea4bd958a21445f8fea86e1602695eb",
      "8b8c7e659c454c028df6f475d71e333b",
      "28aedb1c552245568c6c47bcf06c9e0d",
      "65f8fa392ef74bb48020a57818ed7d1c",
      "ed2450d33b20459bb177e725709d1fb7",
      "726c7e3fd5ad4dcca6ca3260fb0405e8",
      "4278d5e48ba845808d5b7943f202684a",
      "a61fbc00a17e4d23984160b3cc38ff66",
      "6f38772b943941f398b710c915d1382f",
      "7d68384cb331484fb7a5ca543f63c2fd",
      "d42ee6d2dd694d19865b8e522511501a",
      "eca623fba081494baf3cc9cd7c2f2f3c",
      "9029041f08b841f1a6d7afe9f18d8ca4",
      "f5245768efbb49f1af7fe44ad59c5e3b",
      "063e6e49016849efb8630120a91ec7f0",
      "b346abdf802b481782849d4f6afa3ac5",
      "0150d30d85264c9090b06a465f859183",
      "9d8068adaf1d4b288c42e93653e066b9",
      "ba5b7533e4014f6b92d65b2a5cd29975",
      "e65e9aa122ed47a59633dfb8319e93c8",
      "6053e80ddd114199b0a7017f05e56aef",
      "76997c1d78a64cd698b10485c976bbe0",
      "f3434a29356f4e1a8802c16f9fb8d39a",
      "0cbd4ac5c2ea41a4a5c55e288216a494"
     ]
    },
    "collapsed": true,
    "id": "nmLTZF2VJhjc",
    "outputId": "af821236-afb2-48a9-b3a2-3ea4d5c074b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  SKIPPING 1500s (already in summary.json) ---\n",
      "---  SKIPPING 1520s (already in summary.json) ---\n",
      "---  SKIPPING 1560s (already in summary.json) ---\n",
      "---  SKIPPING 1600s (already in summary.json) ---\n",
      "---  SKIPPING 1610s (already in summary.json) ---\n",
      "---  SKIPPING 1620s (already in summary.json) ---\n",
      "---  SKIPPING 1630s (already in summary.json) ---\n",
      "---  SKIPPING 1640s (already in summary.json) ---\n",
      "---  SKIPPING 1650s (already in summary.json) ---\n",
      "---  SKIPPING 1660s (already in summary.json) ---\n",
      "---  SKIPPING 1670s (already in summary.json) ---\n",
      "---  SKIPPING 1680s (already in summary.json) ---\n",
      "---  SKIPPING 1690s (already in summary.json) ---\n",
      "---  SKIPPING 1700s (already in summary.json) ---\n",
      "---  SKIPPING 1710s (already in summary.json) ---\n",
      "---  SKIPPING 1720s (already in summary.json) ---\n",
      "---  SKIPPING 1730s (already in summary.json) ---\n",
      "---  SKIPPING 1740s (already in summary.json) ---\n",
      "---  SKIPPING 1750s (already in summary.json) ---\n",
      "---  SKIPPING 1760s (already in summary.json) ---\n",
      "---  SKIPPING 1770s (already in summary.json) ---\n",
      "---  SKIPPING 1780s (already in summary.json) ---\n",
      "---  SKIPPING 1790s (already in summary.json) ---\n",
      "---  SKIPPING 1800s (already in summary.json) ---\n",
      "---  SKIPPING 1810s (already in summary.json) ---\n",
      "---  SKIPPING 1820s (already in summary.json) ---\n",
      "---  SKIPPING 1830s (already in summary.json) ---\n",
      "---  SKIPPING 1840s (already in summary.json) ---\n",
      "---  SKIPPING 1850s (already in summary.json) ---\n",
      "---  SKIPPING 1860s (already in summary.json) ---\n",
      "---  SKIPPING 1870s (already in summary.json) ---\n",
      "---  SKIPPING 1880s (already in summary.json) ---\n",
      "---  SKIPPING 1890s (already in summary.json) ---\n",
      "---  SKIPPING 1900s (already in summary.json) ---\n",
      "---  SKIPPING 1910s (already in summary.json) ---\n",
      "\n",
      "---  STARTING VIDEO FOR 1930s ---\n",
      "Saving assets to: TroyHistory/1930s\n",
      "Directing script for 1930ss...\n",
      "Input facts length is 470. Requesting 5 scenes.\n",
      "Title: Troy's Great Shrink: The Fabric of Innovation (5 scenes)\n",
      "AI-Selected Voice ID: JBFqnCBsd6RMkjVDRZzb\n",
      "Generating audio for each scene...\n",
      "Using AI-selected voice ID: JBFqnCBsd6RMkjVDRZzb\n",
      "  Audio saved as TroyHistory/1930s/narration_scene_1.mp3\n",
      "  Audio saved as TroyHistory/1930s/narration_scene_2.mp3\n",
      "  Audio saved as TroyHistory/1930s/narration_scene_3.mp3\n",
      "  Audio saved as TroyHistory/1930s/narration_scene_4.mp3\n",
      "  Audio saved as TroyHistory/1930s/narration_scene_5.mp3\n",
      "Generating static images...\n",
      "Generating image for scene 1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36caf37e098d413a9f6e3d2137e40a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TroyHistory/1930s/scene_1.png\n",
      "Generating image for scene 2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756a1f1aece242ffb9f3ca3a739e9633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TroyHistory/1930s/scene_2.png\n",
      "Generating image for scene 3...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7cbc446eef4979b4b5688df5c0467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TroyHistory/1930s/scene_3.png\n",
      "Generating image for scene 4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28aedb1c552245568c6c47bcf06c9e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TroyHistory/1930s/scene_4.png\n",
      "Generating image for scene 5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5245768efbb49f1af7fe44ad59c5e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved TroyHistory/1930s/scene_5.png\n",
      "Assembling video with perfect sync (static images)...\n",
      "\n",
      "---  SUCCESSFULLY CREATED: TroyHistory/1930s_Troy's_Great_Shrink__The_Fabric_of_Innovation.mp4 ---\n",
      "Cleaning up intermediate audio files...\n",
      "---  SKIPPING 1940s (already in summary.json) ---\n",
      "---  SKIPPING 1950s (already in summary.json) ---\n",
      "---  SKIPPING 1960s (already in summary.json) ---\n",
      "---  SKIPPING 1970s (already in summary.json) ---\n",
      "---  SKIPPING 1980s (already in summary.json) ---\n",
      "---  SKIPPING 1990s (already in summary.json) ---\n",
      "---  SKIPPING 2000s (already in summary.json) ---\n",
      "---  SKIPPING 2010s (already in summary.json) ---\n",
      "---  SKIPPING 2020s (already in summary.json) ---\n",
      "\n",
      "--- All videos generated! ---\n"
     ]
    }
   ],
   "source": [
    "# --- Main Loop (Run per decade) ---\n",
    "for decade, facts_string in decade_data.items():\n",
    "\n",
    "    if str(decade) in completed_decades:\n",
    "        print(f\"---  SKIPPING {decade} (already in summary.json) ---\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n---  STARTING VIDEO FOR {decade} ---\")\n",
    "\n",
    "    decade_output_dir = os.path.join(MAIN_OUTPUT_FOLDER, str(decade))\n",
    "    os.makedirs(decade_output_dir, exist_ok=True)\n",
    "    print(f\"Saving assets to: {decade_output_dir}\")\n",
    "\n",
    "    narration_files = []\n",
    "    image_files = []\n",
    "\n",
    "    try:\n",
    "        # Step 2: Director\n",
    "        video_plan = run_director_step(decade, facts_string, director_model, voice_list_string)\n",
    "\n",
    "        # Step 3: Narrator\n",
    "        narration_files = run_narrator_step(video_plan, elevenlabs_client, decade_output_dir)\n",
    "\n",
    "        # Step 4: Artist\n",
    "        image_files = run_artist_step(video_plan, artist_pipe, decade_output_dir)\n",
    "\n",
    "        # Step 5: Editor\n",
    "        output_filename = run_editor_step(video_plan, decade, image_files, narration_files, MAIN_OUTPUT_FOLDER)\n",
    "\n",
    "        if output_filename:\n",
    "            print(f\"\\n---  SUCCESSFULLY CREATED: {output_filename} ---\")\n",
    "            all_summaries.append({\n",
    "                    \"decade\": decade,\n",
    "                    \"summary\": video_plan['narration_script'],\n",
    "                    \"video_filename\": output_filename,\n",
    "                    \"voice_id_used\": video_plan.get('voice_id')\n",
    "                })\n",
    "            print(\"Cleaning up intermediate audio files...\")\n",
    "            for f in narration_files:\n",
    "                try:\n",
    "                    os.remove(f)\n",
    "                except:\n",
    "                    pass # Ignore errors\n",
    "        else:\n",
    "            print(f\"\\n---  SKIPPED video for {decade} (no images generated) ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # This robust error handling means one bad decade won't stop the whole script\n",
    "        print(f\"\\n---  FAILED to create video for {decade}: {e} ---\")\n",
    "        print(\"Continuing to next decade...\")\n",
    "\n",
    "print(\"\\n--- All videos generated! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0gX4ESKbxkvT",
    "outputId": "fff33f2c-24a2-494e-9795-71438548e04f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving final summary to TroyHistory/summary_of_all_videos.json...\n",
      "Summary file saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Save the final JSON summary ---\n",
    "if all_summaries:\n",
    "    summary_filename = os.path.join(MAIN_OUTPUT_FOLDER, \"summary_of_all_videos.json\")\n",
    "    print(f\"Saving final summary to {summary_filename}...\")\n",
    "    try:\n",
    "        with open(summary_filename, 'w') as f:\n",
    "            json.dump(all_summaries, f, indent=4)\n",
    "        print(\"Summary file saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving summary file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "H-zYcbG9Glvi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
